---
title: "Análisis de Modelos"
author: "Gustavo Cruz; Pedro Guzman"
date: "`r Sys.Date()`"
output: html_document
---
## Repositorio
https://github.com/PedroPabloGuzmanMayen/Proyecto2_MD

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Carga de Librerías y Datos

```{r}
library(tidyverse)
library(caret)
library(cluster)
library(factoextra)
library(dplyr)
library(car)
library(Metrics)
library(ggplot2)
library(glmnet)
library(gridExtra)

train <- read.csv("train.csv")
test <- read.csv("test.csv")

set.seed(2301)
trainIndex <- createDataPartition(train$SalePrice, p = 0.8, list = FALSE)
train_set <- train[trainIndex, ]
test_set <- train[-trainIndex, ]
```

##Análisis exploratorio

##Análisis de las variables

### Variables cuantitativas: 
- **SalesPrice**: es una variable continua que representa el precio de cada vivienda en dólares. 
- **Lot frontage**: es una variable continua que representa la cantidad de pies conectadas a la vivienda. 
- **Lot Area**: es una variable continua que representa el área de la vivienda en pies cuadrados. 
- **YearBuilt**: es una variable discreta que representa el año en el que se construyó la vivienda
- **YearRemodAdd**: discreta, representa el año en el que se remodeló la vivienda.
- **BsmtFinSF1**: continua, son los pies cuadrados de tipo 1 terminados. 
- **MasVnrArea**: continua, representa, en pies cuadrados, el área del revestimiento de mampostería. 
- **BsmtFinSF2**: continua, son los pies cuadrados de tipo 2 terminados.
- **BsmtUnfSF**: continua, son los pies cuadrados sin terminar en el sótano. 
- **TotalBsmtSF**: continua, representa, en pues cuadrados, el área total del sótano de la vivienda. 
- **1stFlrSF**: continua, representa la cantidad de pies cuadrados del primer piso.
- **2ndFlrSF**: continua, representa la cantidad de pies cuadrados del segundo piso. 
- **LowQualFinSF**: continua, representa la cantidad de piees cuadrados terminados en todos los pisos de la vivienda.
- **GrLivArea**: continua, representa la cantidad de área sobre e nivel del suelo habitable en pies cuadrados.
- **BsmtFullBath**: discreta, la cantidad de baños con ducha en el sótano de la vivienda. 
- **BsmtHalfBath**: discerta, se refiere a la cantidad de baños sin ducha de la vivienda. 
- **FullBath**: discreta, se refiere a la cantidadde baños con ducha sobre el nivel del suelo. 
- **HalfBath**: discreta, es la cantidad de baños sin ducha sobre el nivel del suelo. 
- **Bedroom**: discreta, la cantidad de dormitorios sobre el nivel del sótano que hay en la vivienda. 
- **Kitchen**: discreta, la cantidad de cocinas de la vivienda. 
- **TotRmsAbvGrd**: discreta, cantidad de cuartos sobre el nivel del suelo de la vivienda. 
- **Fireplaces**: discreta, la cantidad de chimeneas que hay
- **GarageYrBlt**: discreta, el año en el que se construyó el garage de la vivienda. 

## Construcción del Modelo

```{r}
lm_opt <- lm(SalePrice ~ GrLivArea + OverallQual + YearBuilt + GarageCars, data = train_set)
summary(lm_opt)
```

## Análisis de los Residuos

```{r}
par(mfrow = c(2, 2))
plot(lm_opt)
par(mfrow = c(1, 1))
```

## **Interpretación de las graficas:**
**En la primera gráfica** (Residuals vs Fitted), observamos que los residuos no están completamente dispersos de manera aleatoria alrededor de la línea horizontal en cero. Hay una ligera curvatura, lo que sugiere una posible no linealidad en los datos. Esto indica que el modelo puede no capturar completamente la relación entre las variables predictoras y el precio de venta.

**La segunda gráfica** (Q-Q Plot) muestra la distribución de los residuos en comparación con una distribución normal teórica. Vemos que los puntos se desvían en los extremos, lo que indica la presencia de colas gruesas y sugiere que los residuos no siguen perfectamente una distribución normal. Esto puede afectar la validez de los intervalos de confianza y pruebas estadísticas en el modelo.

**En la tercera gráfica** (Scale-Location), los residuos tienden a aumentar en variabilidad a medida que aumentan los valores ajustados. Esto sugiere heterocedasticidad, es decir, la varianza de los errores no es constante. Idealmente, deberíamos ver una distribución uniforme en la dispersión de los puntos.

**La gráfica de Residuals vs Leverage** nos ayuda a identificar puntos influyentes en el modelo. Se observan algunos puntos con alta influencia, señalados por el umbral de Cook's Distance. Estos valores atípicos pueden estar afectando los coeficientes del modelo, y se recomienda analizarlos individualmente para decidir si deben ser eliminados o si es necesario un modelo más robusto.

## Evaluación del Desempeño del Modelo

```{r}
preds <- predict(lm_opt, newdata = test_set)

mae_val <- mae(test_set$SalePrice, preds)
rmse_val <- rmse(test_set$SalePrice, preds)
r2_val <- cor(test_set$SalePrice, preds)^2

cat("MAE:", mae_val, "\n")
cat("RMSE:", rmse_val, "\n")
cat("R²:", r2_val, "\n")
```

Para evaluar la precisión del modelo, utilizamos tres métricas: MAE (Error Absoluto Medio), RMSE (Raíz del Error Cuadrático Medio) y R² (Coeficiente de Determinación).

- MAE: 25,446.3 → En promedio, el modelo tiene un error absoluto de aproximadamente 25,446 dólares en la predicción del precio de venta. Esto indica el margen de error esperado en una estimación individual.
- RMSE: 38,687.16 → El RMSE mide la dispersión de los errores y penaliza más los errores grandes. Un RMSE más bajo es mejor, pero en este caso indica que aún hay errores significativos en la predicción de los precios.
- R²: 0.7155 → Esto significa que el modelo explica aproximadamente el 71.55% de la variabilidad en los precios de venta de las propiedades. Aunque es un buen valor, todavía hay un 28.45% de variabilidad no explicada, lo que sugiere que otras variables podrían mejorar el modelo.

## División en Conjuntos de Entrenamiento y Prueba para Análisis Adicional
```{r}
set.seed(3915)
trainIndex <- createDataPartition(train$SalePrice, p = 0.8, list = FALSE)
train_set <- train[trainIndex, ]
test_set <- train[-trainIndex, ]
```

## Eliminación de variables con un solo nivel
```{r}
unique_counts <- sapply(train_set, function(x) length(unique(x)))
problematic_vars <- names(unique_counts[unique_counts == 1])
if(length(problematic_vars) > 0) {
  train_set <- train_set[, !(names(train_set) %in% problematic_vars)]
  test_set <- test_set[, !(names(test_set) %in% problematic_vars)]
  cat("Variables eliminadas por tener un solo nivel:", problematic_vars, "\n")
} else {
  cat("No se encontraron variables con un solo nivel.\n")
}
```

## Eliminación de variables categóricas con un solo nivel
```{r}
# Identificar variables de tipo factor
cat_vars <- names(which(sapply(train_set, is.factor)))

# Verificar si hay factores con un solo nivel
if(length(cat_vars) > 0) {
  cat_vars_unicas <- character(0)
  for(col in cat_vars) {
    if(length(unique(train_set[[col]])) == 1) {
      cat_vars_unicas <- c(cat_vars_unicas, col)
    }
  }
  
  if(length(cat_vars_unicas) > 0) {
    train_set <- train_set[, !(names(train_set) %in% cat_vars_unicas)]
    test_set <- test_set[, !(names(test_set) %in% cat_vars_unicas)]
    cat("Variables categóricas eliminadas por tener un solo nivel:", cat_vars_unicas, "\n")
  } else {
    cat("No se encontraron variables categóricas con un solo nivel.\n")
  }
} else {
  cat("No se encontraron variables de tipo factor en el conjunto de datos.\n")
}
```

## Manejo de Valores Faltantes
```{r}
# Verificamos valores faltantes en conjuntos de entrenamiento y prueba
na_count_train <- colSums(is.na(train_set))
na_count_test <- colSums(is.na(test_set))

# Mostramos las variables con valores faltantes
na_vars_train <- names(na_count_train[na_count_train > 0])
na_vars_test <- names(na_count_test[na_count_test > 0])

cat("Variables con valores faltantes en train_set:", 
    ifelse(length(na_vars_train) > 0, paste(na_vars_train, collapse=", "), "Ninguna"), "\n")
cat("Variables con valores faltantes en test_set:", 
    ifelse(length(na_vars_test) > 0, paste(na_vars_test, collapse=", "), "Ninguna"), "\n")

# Imputación simple para variables numéricas (media)
for(col in na_vars_train) {
  if(is.numeric(train_set[[col]])) {
    mean_val <- mean(train_set[[col]], na.rm = TRUE)
    train_set[[col]][is.na(train_set[[col]])] <- mean_val
    if(col %in% names(test_set)) {
      test_set[[col]][is.na(test_set[[col]])] <- mean_val
    }
  } else if(is.factor(train_set[[col]])) {
    # Imputación para variables categóricas (moda)
    levels_count <- table(train_set[[col]], useNA = "no")
    if(length(levels_count) > 0) {
      mode_val <- names(which.max(levels_count))
      train_set[[col]][is.na(train_set[[col]])] <- mode_val
      if(col %in% names(test_set)) {
        test_set[[col]][is.na(test_set[[col]])] <- mode_val
      }
    }
  }
}
```

## Definición de Modelos de Regresión
```{r}
# Aseguramos que las variables predictoras son equivalentes en ambos conjuntos
common_vars <- intersect(names(train_set), names(test_set))
train_set <- train_set[, common_vars]
test_set <- test_set[, common_vars]

# Modelo 1: Regresión Simple
lm1 <- lm(SalePrice ~ GrLivArea, data = train_set)
summary(lm1)

# Modelo 2: Regresión Múltiple con variables seleccionadas
lm2 <- lm(SalePrice ~ GrLivArea + OverallQual + YearBuilt + GarageCars, data = train_set)
summary(lm2)

```

## Evaluación de Modelos
```{r}
modelos <- list(lm1, lm2)
nombres_modelos <- c("Regresión Simple", "Regresión Múltiple", "Modelo Completo")
resultados <- data.frame(Modelo = character(), MAE = numeric(), RMSE = numeric(), R2 = numeric(), stringsAsFactors = FALSE)

for (i in 1:length(modelos)) {
  tryCatch({
    preds <- predict(modelos[[i]], newdata = test_set)
    mae_val <- mae(test_set$SalePrice, preds)
    rmse_val <- rmse(test_set$SalePrice, preds)
    r2_val <- cor(test_set$SalePrice, preds)^2
    
    resultados <- rbind(resultados, data.frame(
      Modelo = nombres_modelos[i],
      MAE = mae_val,
      RMSE = rmse_val,
      R2 = r2_val,
      stringsAsFactors = FALSE
    ))
  }, error = function(e) {
    cat("Error al evaluar el modelo", nombres_modelos[i], ":", e$message, "\n")
  })
}
```

## Visualización de Resultados
```{r}
if(nrow(resultados) > 0) {
  print(resultados)
  
  # Gráfico de barras para RMSE
  ggplot(resultados, aes(x = Modelo, y = RMSE, fill = Modelo)) +
    geom_bar(stat = "identity") +
    theme_minimal() +
    labs(title = "Comparación de Modelos - RMSE", y = "RMSE", x = "Modelo") +
    theme(legend.position = "none")
  
  # Gráfico de barras para R²
  ggplot(resultados, aes(x = Modelo, y = R2, fill = Modelo)) +
    geom_bar(stat = "identity") +
    theme_minimal() +
    labs(title = "Comparación de Modelos - R²", y = "R²", x = "Modelo") +
    theme(legend.position = "none")
} else {
  cat("No se pudieron evaluar los modelos correctamente.\n")
}
```

## Conclusiones

### Análisis de Datos

- Se identificaron 19 variables con valores faltantes en ambos conjuntos (entrenamiento y prueba)
- Las variables con datos faltantes incluyen principalmente características estructurales como: LotFrontage, MasVnrType, elementos del sótano (BsmtQual, BsmtCond, etc.), garaje y características opcionales (PoolQC, Fence)

### Modelo de Regresión Simple

**Variable predictora:** GrLivArea (superficie habitable)
Resultados:

**Coeficiente de GrLivArea:** 105.699 (p < 2e-16)
**R² ajustado: 0.5043**
**Error estándar residual:** 56,830

Por cada pie cuadrado adicional, el precio de venta aumenta aproximadamente $105.70

### Modelo de Regresión Múltiple

**Variables predictoras:** GrLivArea, OverallQual, YearBuilt, GarageCars
Resultados:

**GrLivArea:** 56.41 (p < 2e-16)
**OverallQual:** 22,570 (p < 2e-16)
**YearBuilt:** 370.3 (p < 1.65e-12)
**GarageCars:** 16,430 (p < 2.12e-14)
**R² ajustado:** 0.7454
**Error estándar residual:** 40,730

## Comparación de Modelos
El modelo múltiple mejora significativamente la capacidad predictiva (R² incrementa de 0.49 a 0.77)
La calidad general de la vivienda (OverallQual) y la superficie habitable son los predictores más influyentes
La reducción del RMSE en aproximadamente 17,000 dólares indica una mejora sustancial en la precisión de las predicciones
El año de construcción y el número de plazas de garaje aportan información valiosa para la predicción de precios

```{r}
set.seed(812)
```

## Análisis de Grupos (K-means)

```{r preparar_datos_cluster}
# Identificar las filas sin NA
filas_completas <- complete.cases(train %>% select_if(is.numeric) %>% select(-SalePrice))
train_completo <- train[filas_completas, ]

datos_cluster <- train_completo %>%
  select_if(is.numeric) %>%
  select(-SalePrice)

datos_cluster_scaled <- scale(datos_cluster)
```

```{r determinar_clusters_optimos, fig.width=10, fig.height=5}
# Determinar el número óptimo de clusters usando el método del codo
p1 <- fviz_nbclust(datos_cluster_scaled, kmeans, method = "wss", k.max = 10) +
  labs(title = "Método del Codo",
       x = "Número de Clusters",
       y = "Suma Total de Cuadrados Dentro de los Grupos") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold", hjust = 0.5))

# Comparacion con método de la silueta
p2 <- fviz_nbclust(datos_cluster_scaled, kmeans, method = "silhouette", k.max = 10) +
  labs(title = "Método de la Silueta",
       x = "Número de Clusters",
       y = "Valor Promedio de la Silueta") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold", hjust = 0.5))
grid.arrange(p1, p2, ncol = 2)
```
Para elegir el k-óptimo, se llevo a cabo la comparación de ambos métodos, para así poder elegir más fácil el cluster correcto.

### Método del Codo (izquierda)
Se observa una disminución rápida en la inercia hasta k=3, luego la reducción es más gradual.
El "codo" parece estar en k=3 o k=4, ya que después la pendiente disminuye menos.

### Coeficiente de Silueta (derecha)
El valor máximo del coeficiente de silueta se encuentra en k=3.
A partir de k=4, el valor comienza a descender, lo que indica que los clusters son menos compactos.

El k-optimo elegido será k=3 debido a que tanto en el método del codo, como en el de silueta lo favorecen.
```{r crear_clusters}
k_optimo <- 3
modelo_kmeans <- kmeans(datos_cluster_scaled, centers = k_optimo, nstart = 25)

train_completo$Cluster <- modelo_kmeans$cluster
```

```{r}
fviz_cluster(modelo_kmeans, data = datos_cluster_scaled,
             palette = "jco",
             geom = "point",
             ellipse.type = "convex",
             ggtheme = theme_minimal()) +
  labs(title = "Agrupación de Casas por Características",
       subtitle = paste("K-means con", k_optimo, "clusters")) +
  theme(plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
        plot.subtitle = element_text(size = 12, hjust = 0.5))
```

```{r}
caracteristicas_por_cluster <- train_completo %>%
  group_by(Cluster) %>%
  summarise(across(where(is.numeric), mean, na.rm = TRUE)) %>%
  mutate(across(where(is.numeric), round, 2))

comparacion_precios <- train_completo %>%
  group_by(Cluster) %>%
  summarise(
    Precio_Medio = mean(SalePrice, na.rm = TRUE),
    Precio_Mediano = median(SalePrice, na.rm = TRUE),
    Desviación_Estándar = sd(SalePrice, na.rm = TRUE),
    Conteo = n()
  ) %>%
  arrange(desc(Precio_Medio))

knitr::kable(comparacion_precios, caption = "Comparación de Precios por Cluster")
```

```{r}
ggplot(train_completo, aes(x = as.factor(Cluster), y = SalePrice, fill = as.factor(Cluster))) +
  geom_boxplot() +
  scale_fill_brewer(palette = "Set1") +
  labs(title = "Distribución de Precios por Cluster",
       x = "Cluster",
       y = "Precio",
       fill = "Cluster") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold", hjust = 0.5))
```

```{r}
datos_largo <- caracteristicas_por_cluster %>%
  pivot_longer(cols = -Cluster, 
               names_to = "Variable", 
               values_to = "Valor")

variables_importantes <- c("LotArea", "GrLivArea", "BedroomAbvGr", "TotalBsmtSF", "YearBuilt", "OverallQual")

ggplot(datos_largo %>% filter(Variable %in% variables_importantes), 
       aes(x = Variable, y = Valor, fill = as.factor(Cluster))) +
  geom_bar(stat = "identity", position = "dodge") +
  scale_fill_brewer(palette = "Set1") +
  labs(title = "Comparación de Características por Cluster",
       x = "Variable",
       y = "Valor Promedio",
       fill = "Cluster") +
  theme_minimal() +
  theme(plot.title = element_text(size = 14, face = "bold", hjust = 0.5),
        axis.text.x = element_text(angle = 45, hjust = 1))
```

### Análisis de Agrupación de Casas por Características y Precios

Se realizó una segmentación de viviendas utilizando el algoritmo K-Means, seleccionando k=3k=3 como el número óptimo de clusters según el método del codo y el coeficiente de silueta. Posteriormente, se analizaron las características de cada cluster en términos de precio medio, mediano y su dispersión.
Distribución de Precios por Cluster

- Cluster 1: Representa viviendas con un precio medio de 240,757 USD y una mediana de 220,000 USD. La desviación estándar de 77,447 USD sugiere una dispersión moderada en los precios.
- Cluster 2: Contiene viviendas con un precio medio de 130,621 USD, significativamente más bajo que los otros clusters. Su mediana es de 131,200 USD, con una desviación estándar de 28,705 USD, lo que indica que los precios son más homogéneos.
- Cluster 3: Abarca viviendas con un precio medio de 229,829 USD y una mediana de 204,875 USD, mostrando una distribución de precios similar a la del Cluster 1. Sin embargo, su desviación estándar de 90,877 USD indica una mayor variabilidad en los precios.

### Comparación de Características por Cluster

- Cluster 1 (rojo): Incluye casas con precios altos y características más destacadas en variables como el tamaño del lote y la calidad de acabados.
- Cluster 2 (azul): Contiene viviendas más económicas con tamaños de lote más pequeños y acabados menos lujosos.
- Cluster 3 (verde): Presenta precios similares al Cluster 1 pero con una mayor dispersión, lo que sugiere una mezcla de viviendas de diferentes categorías.

En resumen, con base a los gráficos generados y la información encontrada, encontramos que:

- Las viviendas de alto valor (Cluster 1): Precios elevados, acabados de mayor calidad.
- Las viviendas económicas (Cluster 2): Precios más bajos y menos variabilidad.
- Las viviendas de precio medio-alto (Cluster 3): Similar al Cluster 1 pero con mayor variabilidad en precios.


