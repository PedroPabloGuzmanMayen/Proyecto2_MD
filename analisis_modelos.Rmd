---
title: "Análisis de Modelos"
author: "Gustavo Cruz; Pedro Guzman"
date: "`r Sys.Date()`"
output: html_document
---
## Repositorio
https://github.com/PedroPabloGuzmanMayen/Proyecto2_MD

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Carga de Librerías y Datos

```{r}
library(tidyverse)
library(caret)
library(cluster)
library(factoextra)
library(dplyr)
library(car)
library(Metrics)
library(ggplot2)

train <- read.csv("train.csv")
test <- read.csv("test.csv")

set.seed(2301)
trainIndex <- createDataPartition(train$SalePrice, p = 0.8, list = FALSE)
train_set <- train[trainIndex, ]
test_set <- train[-trainIndex, ]
```

##Análisis exploratorio

##Análisis de las variables

### Variables cuantitativas: 
- **SalesPrice**: es una variable continua que representa el precio de cada vivienda en dólares. 
- **Lot frontage**: es una variable continua que representa la cantidad de pies conectadas a la vivienda. 
- **Lot Area**: es una variable continua que representa el área de la vivienda en pies cuadrados. 
- **YearBuilt**: es una variable discreta que representa el año en el que se construyó la vivienda
- **YearRemodAdd**: discreta, representa el año en el que se remodeló la vivienda.
- **BsmtFinSF1**: continua, son los pies cuadrados de tipo 1 terminados. 
- **MasVnrArea**: continua, representa, en pies cuadrados, el área del revestimiento de mampostería. 
- **BsmtFinSF2**: continua, son los pies cuadrados de tipo 2 terminados.
- **BsmtUnfSF**: continua, son los pies cuadrados sin terminar en el sótano. 
- **TotalBsmtSF**: continua, representa, en pues cuadrados, el área total del sótano de la vivienda. 
- **1stFlrSF**: continua, representa la cantidad de pies cuadrados del primer piso.
- **2ndFlrSF**: continua, representa la cantidad de pies cuadrados del segundo piso. 
- **LowQualFinSF**: continua, representa la cantidad de piees cuadrados terminados en todos los pisos de la vivienda.
- **GrLivArea**: continua, representa la cantidad de área sobre e nivel del suelo habitable en pies cuadrados.
- **BsmtFullBath**: discreta, la cantidad de baños con ducha en el sótano de la vivienda. 
- **BsmtHalfBath**: discerta, se refiere a la cantidad de baños sin ducha de la vivienda. 
- **FullBath**: discreta, se refiere a la cantidadde baños con ducha sobre el nivel del suelo. 
- **HalfBath**: discreta, es la cantidad de baños sin ducha sobre el nivel del suelo. 
- **Bedroom**: discreta, la cantidad de dormitorios sobre el nivel del sótano que hay en la vivienda. 
- **Kitchen**: discreta, la cantidad de cocinas de la vivienda. 
- **TotRmsAbvGrd**: discreta, cantidad de cuartos sobre el nivel del suelo de la vivienda. 
- **Fireplaces**: discreta, la cantidad de chimeneas que hay
- **GarageYrBlt**: discreta, el año en el que se construyó el garage de la vivienda. 

## Construcción del Modelo

```{r}
lm_opt <- lm(SalePrice ~ GrLivArea + OverallQual + YearBuilt + GarageCars, data = train_set)
summary(lm_opt)
```

## Análisis de los Residuos

```{r}
par(mfrow = c(2, 2))
plot(lm_opt)
par(mfrow = c(1, 1))
```

## **Interpretación de las graficas:**
**En la primera gráfica** (Residuals vs Fitted), observamos que los residuos no están completamente dispersos de manera aleatoria alrededor de la línea horizontal en cero. Hay una ligera curvatura, lo que sugiere una posible no linealidad en los datos. Esto indica que el modelo puede no capturar completamente la relación entre las variables predictoras y el precio de venta.

**La segunda gráfica** (Q-Q Plot) muestra la distribución de los residuos en comparación con una distribución normal teórica. Vemos que los puntos se desvían en los extremos, lo que indica la presencia de colas gruesas y sugiere que los residuos no siguen perfectamente una distribución normal. Esto puede afectar la validez de los intervalos de confianza y pruebas estadísticas en el modelo.

**En la tercera gráfica** (Scale-Location), los residuos tienden a aumentar en variabilidad a medida que aumentan los valores ajustados. Esto sugiere heterocedasticidad, es decir, la varianza de los errores no es constante. Idealmente, deberíamos ver una distribución uniforme en la dispersión de los puntos.

**La gráfica de Residuals vs Leverage** nos ayuda a identificar puntos influyentes en el modelo. Se observan algunos puntos con alta influencia, señalados por el umbral de Cook's Distance. Estos valores atípicos pueden estar afectando los coeficientes del modelo, y se recomienda analizarlos individualmente para decidir si deben ser eliminados o si es necesario un modelo más robusto.

## Evaluación del Desempeño del Modelo

```{r}
preds <- predict(lm_opt, newdata = test_set)

mae_val <- mae(test_set$SalePrice, preds)
rmse_val <- rmse(test_set$SalePrice, preds)
r2_val <- cor(test_set$SalePrice, preds)^2

cat("MAE:", mae_val, "\n")
cat("RMSE:", rmse_val, "\n")
cat("R²:", r2_val, "\n")
```

Para evaluar la precisión del modelo, utilizamos tres métricas: MAE (Error Absoluto Medio), RMSE (Raíz del Error Cuadrático Medio) y R² (Coeficiente de Determinación).

- MAE: 25,446.3 → En promedio, el modelo tiene un error absoluto de aproximadamente 25,446 dólares en la predicción del precio de venta. Esto indica el margen de error esperado en una estimación individual.
- RMSE: 38,687.16 → El RMSE mide la dispersión de los errores y penaliza más los errores grandes. Un RMSE más bajo es mejor, pero en este caso indica que aún hay errores significativos en la predicción de los precios.
- R²: 0.7155 → Esto significa que el modelo explica aproximadamente el 71.55% de la variabilidad en los precios de venta de las propiedades. Aunque es un buen valor, todavía hay un 28.45% de variabilidad no explicada, lo que sugiere que otras variables podrían mejorar el modelo.

## División en Conjuntos de Entrenamiento y Prueba para Análisis Adicional
```{r}
set.seed(3915)
trainIndex <- createDataPartition(train$SalePrice, p = 0.8, list = FALSE)
train_set <- train[trainIndex, ]
test_set <- train[-trainIndex, ]
```

## Eliminación de variables con un solo nivel
```{r}
unique_counts <- sapply(train_set, function(x) length(unique(x)))
problematic_vars <- names(unique_counts[unique_counts == 1])
if(length(problematic_vars) > 0) {
  train_set <- train_set[, !(names(train_set) %in% problematic_vars)]
  test_set <- test_set[, !(names(test_set) %in% problematic_vars)]
  cat("Variables eliminadas por tener un solo nivel:", problematic_vars, "\n")
} else {
  cat("No se encontraron variables con un solo nivel.\n")
}
```

## Eliminación de variables categóricas con un solo nivel
```{r}
# Identificar variables de tipo factor
cat_vars <- names(which(sapply(train_set, is.factor)))

# Verificar si hay factores con un solo nivel
if(length(cat_vars) > 0) {
  cat_vars_unicas <- character(0)
  for(col in cat_vars) {
    if(length(unique(train_set[[col]])) == 1) {
      cat_vars_unicas <- c(cat_vars_unicas, col)
    }
  }
  
  if(length(cat_vars_unicas) > 0) {
    train_set <- train_set[, !(names(train_set) %in% cat_vars_unicas)]
    test_set <- test_set[, !(names(test_set) %in% cat_vars_unicas)]
    cat("Variables categóricas eliminadas por tener un solo nivel:", cat_vars_unicas, "\n")
  } else {
    cat("No se encontraron variables categóricas con un solo nivel.\n")
  }
} else {
  cat("No se encontraron variables de tipo factor en el conjunto de datos.\n")
}
```

## Manejo de Valores Faltantes
```{r}
# Verificamos valores faltantes en conjuntos de entrenamiento y prueba
na_count_train <- colSums(is.na(train_set))
na_count_test <- colSums(is.na(test_set))

# Mostramos las variables con valores faltantes
na_vars_train <- names(na_count_train[na_count_train > 0])
na_vars_test <- names(na_count_test[na_count_test > 0])

cat("Variables con valores faltantes en train_set:", 
    ifelse(length(na_vars_train) > 0, paste(na_vars_train, collapse=", "), "Ninguna"), "\n")
cat("Variables con valores faltantes en test_set:", 
    ifelse(length(na_vars_test) > 0, paste(na_vars_test, collapse=", "), "Ninguna"), "\n")

# Imputación simple para variables numéricas (media)
for(col in na_vars_train) {
  if(is.numeric(train_set[[col]])) {
    mean_val <- mean(train_set[[col]], na.rm = TRUE)
    train_set[[col]][is.na(train_set[[col]])] <- mean_val
    if(col %in% names(test_set)) {
      test_set[[col]][is.na(test_set[[col]])] <- mean_val
    }
  } else if(is.factor(train_set[[col]])) {
    # Imputación para variables categóricas (moda)
    levels_count <- table(train_set[[col]], useNA = "no")
    if(length(levels_count) > 0) {
      mode_val <- names(which.max(levels_count))
      train_set[[col]][is.na(train_set[[col]])] <- mode_val
      if(col %in% names(test_set)) {
        test_set[[col]][is.na(test_set[[col]])] <- mode_val
      }
    }
  }
}
```

## Definición de Modelos de Regresión
```{r}
# Aseguramos que las variables predictoras son equivalentes en ambos conjuntos
common_vars <- intersect(names(train_set), names(test_set))
train_set <- train_set[, common_vars]
test_set <- test_set[, common_vars]

# Modelo 1: Regresión Simple
lm1 <- lm(SalePrice ~ GrLivArea, data = train_set)
summary(lm1)

# Modelo 2: Regresión Múltiple con variables seleccionadas
lm2 <- lm(SalePrice ~ GrLivArea + OverallQual + YearBuilt + GarageCars, data = train_set)
summary(lm2)

```

## Evaluación de Modelos
```{r}
modelos <- list(lm1, lm2)
nombres_modelos <- c("Regresión Simple", "Regresión Múltiple", "Modelo Completo")
resultados <- data.frame(Modelo = character(), MAE = numeric(), RMSE = numeric(), R2 = numeric(), stringsAsFactors = FALSE)

for (i in 1:length(modelos)) {
  tryCatch({
    preds <- predict(modelos[[i]], newdata = test_set)
    mae_val <- mae(test_set$SalePrice, preds)
    rmse_val <- rmse(test_set$SalePrice, preds)
    r2_val <- cor(test_set$SalePrice, preds)^2
    
    resultados <- rbind(resultados, data.frame(
      Modelo = nombres_modelos[i],
      MAE = mae_val,
      RMSE = rmse_val,
      R2 = r2_val,
      stringsAsFactors = FALSE
    ))
  }, error = function(e) {
    cat("Error al evaluar el modelo", nombres_modelos[i], ":", e$message, "\n")
  })
}
```

## Visualización de Resultados
```{r}
if(nrow(resultados) > 0) {
  print(resultados)
  
  # Gráfico de barras para RMSE
  ggplot(resultados, aes(x = Modelo, y = RMSE, fill = Modelo)) +
    geom_bar(stat = "identity") +
    theme_minimal() +
    labs(title = "Comparación de Modelos - RMSE", y = "RMSE", x = "Modelo") +
    theme(legend.position = "none")
  
  # Gráfico de barras para R²
  ggplot(resultados, aes(x = Modelo, y = R2, fill = Modelo)) +
    geom_bar(stat = "identity") +
    theme_minimal() +
    labs(title = "Comparación de Modelos - R²", y = "R²", x = "Modelo") +
    theme(legend.position = "none")
} else {
  cat("No se pudieron evaluar los modelos correctamente.\n")
}
```

```{r}
# Asegurar que los datos están cargados
if (!exists("house_prices")) {
  house_prices <- read.csv("house_prices.csv")
}

# Preprocesamiento: seleccionar variables numéricas
numeric_data <- house_prices %>% select(where(is.numeric)) %>% drop_na()

# K-Means Clustering
set.seed(123)  # Reproducibilidad
k <- 3  # Número de clusters
kmeans_model <- kmeans(numeric_data, centers = k, nstart = 25)
numeric_data$cluster <- as.factor(kmeans_model$cluster)

# Visualización Clustering (ejemplo con primeras dos variables principales)
ggplot(numeric_data, aes(x = numeric_data[,1], y = numeric_data[,2], color = cluster)) +
  geom_point() +
  labs(title = "K-Means Clustering")

# Ridge Regression para evitar sobreajuste
set.seed(123)
data_split <- initial_split(numeric_data, prop = 0.8)
train_data <- training(data_split)
test_data <- testing(data_split)

ridge_recipe <- recipe(SalePrice ~ ., data = train_data) %>%
  step_normalize(all_predictors())

ridge_spec <- linear_reg(penalty = 0.1, mixture = 0) %>% 
  set_engine("glmnet")

ridge_workflow <- workflow() %>% 
  add_recipe(ridge_recipe) %>% 
  add_model(ridge_spec)

ridge_fit <- fit(ridge_workflow, data = train_data)

# Evaluación
ridge_results <- predict(ridge_fit, test_data) %>%
  bind_cols(test_data) %>%
  metrics(truth = SalePrice, estimate = .pred)

print(ridge_results)

```


## Conclusiones

### Análisis de Datos

- Se identificaron 19 variables con valores faltantes en ambos conjuntos (entrenamiento y prueba)
- Las variables con datos faltantes incluyen principalmente características estructurales como: LotFrontage, MasVnrType, elementos del sótano (BsmtQual, BsmtCond, etc.), garaje y características opcionales (PoolQC, Fence)

### Modelo de Regresión Simple

**Variable predictora:** GrLivArea (superficie habitable)
Resultados:

**Coeficiente de GrLivArea:** 105.699 (p < 2e-16)
**R² ajustado: 0.5043**
**Error estándar residual:** 56,830

Por cada pie cuadrado adicional, el precio de venta aumenta aproximadamente $105.70

### Modelo de Regresión Múltiple

**Variables predictoras:** GrLivArea, OverallQual, YearBuilt, GarageCars
Resultados:

**GrLivArea:** 56.41 (p < 2e-16)
**OverallQual:** 22,570 (p < 2e-16)
**YearBuilt:** 370.3 (p < 1.65e-12)
**GarageCars:** 16,430 (p < 2.12e-14)
**R² ajustado:** 0.7454
**Error estándar residual:** 40,730

## Comparación de Modelos
El modelo múltiple mejora significativamente la capacidad predictiva (R² incrementa de 0.49 a 0.77)
La calidad general de la vivienda (OverallQual) y la superficie habitable son los predictores más influyentes
La reducción del RMSE en aproximadamente 17,000 dólares indica una mejora sustancial en la precisión de las predicciones
El año de construcción y el número de plazas de garaje aportan información valiosa para la predicción de precios